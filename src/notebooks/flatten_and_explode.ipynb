{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1368a582-d012-4d84-8005-bfc47fd702fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a12ec2e196df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrayType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStructType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexplode_outer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays_zip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas_udf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.types import ArrayType, StructType\n",
    "from pyspark.sql.functions import explode_outer, col, arrays_zip\n",
    "import os\n",
    "from pyspark.sql.functions import pandas_udf, explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "46abb9b3-76d0-4616-b025-6fe16d74b057",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/Patient_1.ndjson\"\n",
    "file_type = \"ndjson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7d085eda-59db-4edc-baf3-8535fe635401",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dbutils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-18ebaf4f61d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdbutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dbfs:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dbfs:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dbutils' is not defined"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"dbfs:\" + file_location)\n",
    "df = spark.read.json(\"dbfs:\" + file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "93599306-137f-411d-8c35-9ebb79e7e8e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Transforms a data frame which contains struct columns into a data frame where\n",
    "each such column is expanded into multiple columns, one for each unique value\n",
    "in the original struct. Columns are prefaced with the parent name for organization.\n",
    "'''\n",
    "def flatten_structs(nested_df):\n",
    "    stack = [((), nested_df)]\n",
    "    columns = []\n",
    "\n",
    "    while len(stack) > 0:\n",
    "        # Grab columns that are already flat and move to final df\n",
    "        parents, df = stack.pop()\n",
    "        flat_cols = [col(\".\".join(parents + (c[0],))).alias(\"_\".join(parents + (c[0],))) for c in df.dtypes if c[1][:6] != \"struct\"]\n",
    "        columns.extend(flat_cols)\n",
    "        \n",
    "        # Recursively collect columns within each struct, searching until\n",
    "        # the projection is flat\n",
    "        nested_cols = [c[0] for c in df.dtypes if c[1][:6] == \"struct\" ]    \n",
    "        for nc in nested_cols:\n",
    "            projected_df = df.select(nc + \".*\")\n",
    "            stack.append((parents + (nc,), projected_df))\n",
    "            \n",
    "    return nested_df.select(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4b79cb27-08b1-4736-b4ff-f1ad75fefa21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Transforms a spark dataframe into an \"exploded\" data frame. To explode a data frame \n",
    "means to add a new row containing identical identifying information to a base row \n",
    "for each array-element encountered in columns whose fields are structs. The result\n",
    "is returned as a dataframe.\n",
    "'''\n",
    "def explode_arrays(df):\n",
    "    flat_cols = [field.name for field in df.schema.fields if type(field.dataType) != ArrayType]\n",
    "    struct_cols = [field.name for field in df.schema.fields if type(field.dataType) == ArrayType]\n",
    "    \n",
    "    # Add new rows for each array element, then select and join with columns\n",
    "    # that are already flat\n",
    "    exploded_df = df.withColumn('vals', explode_outer(arrays_zip(*struct_cols))) \\\n",
    "           .select(*flat_cols,'vals.*') \\\n",
    "           .fillna('', subset=struct_cols)\n",
    "    return exploded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "58b88ca4-f51d-4ec2-9852-e0af3628ca6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "A wrapper function to perform full flattening of an input spark data frame.\n",
    "Struct columns are separated out into multiple columns, and then the intermediate\n",
    "expanded data frame is exploded so that each new element encountered generates a \n",
    "new row.\n",
    "'''\n",
    "def flatten_df(dfflat):\n",
    "    while len([field.name for field in dfflat.schema.fields if type(field.dataType) == StructType or type(field.dataType) == ArrayType ]) !=0 :\n",
    "        dfflat = flatten_structs(dfflat)\n",
    "        dfflat = explode_arrays(dfflat)\n",
    "    return dfflat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1af9907f-162a-45d6-98e9-7f7025571bd2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Generates a DDL \"create-table\" string from a flattened spark dataframe. The result\n",
    "of this function is a statement of the form:\n",
    "\n",
    "  CREATE TABLE [table_name] (\n",
    "    [field1] nvarchar(50),\n",
    "    [field2] nvarchar(50),\n",
    "    ...\n",
    "  )\n",
    "  \n",
    "For type safety reasons, all fields in the created DDL are saved as nvarchar(50).\n",
    "'''\n",
    "def generate_ddl(df, tblname):\n",
    "    createtbl = 'CREATE TABLE [' + tblname +  '] ( \\n'\n",
    "    num_columns = len(dfflat.columns)\n",
    "    for i, y in enumerate(dfflat.columns):\n",
    "        if i == num_columns-1:\n",
    "            column_name = '\\t['+ y + '] nvarchar(50)); \\n\\n'\n",
    "        else:\n",
    "            column_name = '\\t[' + y + '] nvarchar(50), \\n'\n",
    "        createtbl += column_name\n",
    "    return createtbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8538fc8b-4dff-4c61-8bc8-cb21031d94b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flatten_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c34791640a95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'flatten_df' is not defined"
     ]
    }
   ],
   "source": [
    "dfflat = flatten_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4a5c98ad-07ec-419d-bc03-b9039f8cb2ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">CREATE TABLE [patient] ( \n",
       "\t[active] nvarchar(50), \n",
       "\t[birthDate] nvarchar(50), \n",
       "\t[deceasedDateTime] nvarchar(50), \n",
       "\t[gender] nvarchar(50), \n",
       "\t[id] nvarchar(50), \n",
       "\t[multipleBirthBoolean] nvarchar(50), \n",
       "\t[resourceType] nvarchar(50), \n",
       "\t[text_div] nvarchar(50), \n",
       "\t[text_status] nvarchar(50), \n",
       "\t[meta_lastUpdated] nvarchar(50), \n",
       "\t[meta_versionId] nvarchar(50), \n",
       "\t[maritalStatus_text] nvarchar(50), \n",
       "\t[maritalStatus_coding_code] nvarchar(50), \n",
       "\t[maritalStatus_coding_display] nvarchar(50), \n",
       "\t[maritalStatus_coding_system] nvarchar(50), \n",
       "\t[telecom_system] nvarchar(50), \n",
       "\t[telecom_use] nvarchar(50), \n",
       "\t[telecom_value] nvarchar(50), \n",
       "\t[name_family] nvarchar(50), \n",
       "\t[name_use] nvarchar(50), \n",
       "\t[identifier_system] nvarchar(50), \n",
       "\t[identifier_value] nvarchar(50), \n",
       "\t[identifier_type_text] nvarchar(50), \n",
       "\t[extension_url] nvarchar(50), \n",
       "\t[extension_valueDecimal] nvarchar(50), \n",
       "\t[extension_valueString] nvarchar(50), \n",
       "\t[extension_valueAddress_city] nvarchar(50), \n",
       "\t[extension_valueAddress_country] nvarchar(50), \n",
       "\t[extension_valueAddress_state] nvarchar(50), \n",
       "\t[communication_language_text] nvarchar(50), \n",
       "\t[address_city] nvarchar(50), \n",
       "\t[address_country] nvarchar(50), \n",
       "\t[address_postalCode] nvarchar(50), \n",
       "\t[address_state] nvarchar(50), \n",
       "\t[name_given] nvarchar(50), \n",
       "\t[name_prefix] nvarchar(50), \n",
       "\t[address_line] nvarchar(50), \n",
       "\t[address_extension_url] nvarchar(50), \n",
       "\t[communication_language_coding_code] nvarchar(50), \n",
       "\t[communication_language_coding_display] nvarchar(50), \n",
       "\t[communication_language_coding_system] nvarchar(50), \n",
       "\t[identifier_type_coding_code] nvarchar(50), \n",
       "\t[identifier_type_coding_display] nvarchar(50), \n",
       "\t[identifier_type_coding_system] nvarchar(50), \n",
       "\t[address_extension_extension_url] nvarchar(50), \n",
       "\t[address_extension_extension_valueDecimal] nvarchar(50)); \n",
       "\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">CREATE TABLE [patient] ( \n\t[active] nvarchar(50), \n\t[birthDate] nvarchar(50), \n\t[deceasedDateTime] nvarchar(50), \n\t[gender] nvarchar(50), \n\t[id] nvarchar(50), \n\t[multipleBirthBoolean] nvarchar(50), \n\t[resourceType] nvarchar(50), \n\t[text_div] nvarchar(50), \n\t[text_status] nvarchar(50), \n\t[meta_lastUpdated] nvarchar(50), \n\t[meta_versionId] nvarchar(50), \n\t[maritalStatus_text] nvarchar(50), \n\t[maritalStatus_coding_code] nvarchar(50), \n\t[maritalStatus_coding_display] nvarchar(50), \n\t[maritalStatus_coding_system] nvarchar(50), \n\t[telecom_system] nvarchar(50), \n\t[telecom_use] nvarchar(50), \n\t[telecom_value] nvarchar(50), \n\t[name_family] nvarchar(50), \n\t[name_use] nvarchar(50), \n\t[identifier_system] nvarchar(50), \n\t[identifier_value] nvarchar(50), \n\t[identifier_type_text] nvarchar(50), \n\t[extension_url] nvarchar(50), \n\t[extension_valueDecimal] nvarchar(50), \n\t[extension_valueString] nvarchar(50), \n\t[extension_valueAddress_city] nvarchar(50), \n\t[extension_valueAddress_country] nvarchar(50), \n\t[extension_valueAddress_state] nvarchar(50), \n\t[communication_language_text] nvarchar(50), \n\t[address_city] nvarchar(50), \n\t[address_country] nvarchar(50), \n\t[address_postalCode] nvarchar(50), \n\t[address_state] nvarchar(50), \n\t[name_given] nvarchar(50), \n\t[name_prefix] nvarchar(50), \n\t[address_line] nvarchar(50), \n\t[address_extension_url] nvarchar(50), \n\t[communication_language_coding_code] nvarchar(50), \n\t[communication_language_coding_display] nvarchar(50), \n\t[communication_language_coding_system] nvarchar(50), \n\t[identifier_type_coding_code] nvarchar(50), \n\t[identifier_type_coding_display] nvarchar(50), \n\t[identifier_type_coding_system] nvarchar(50), \n\t[address_extension_extension_url] nvarchar(50), \n\t[address_extension_extension_valueDecimal] nvarchar(50)); \n\n\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ddl = generate_ddl(dfflat, \"patient\")\n",
    "print(ddl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f823ba96-cd89-478a-b171-2858466a0ca9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "flatten_and_explode",
   "notebookOrigID": 1150546841339958,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
